# Guia Completo de Setup em Desenvolvimento

Instru√ß√µes passo a passo para executar o Vizier Med Backend em desenvolvimento local.

## üìã Pr√©-requisitos

### Instala√ß√£o Necess√°ria

1. **Docker** (vers√£o 20.10+)
   ```bash
   # Verificar instala√ß√£o
   docker --version
   
   # Download: https://www.docker.com/products/docker-desktop
   ```

2. **Docker Compose** (vers√£o 2.0+)
   ```bash
   # Verificar instala√ß√£o
   docker-compose --version
   
   # J√° vem com Docker Desktop
   ```

3. **Git** (para clonar/versionar)
   ```bash
   git --version
   ```

### Opcional (para desenvolvimento sem Docker)

- Python 3.11+
- PostgreSQL 15+
- Redis 7+

## üöÄ Execu√ß√£o R√°pida (5 minutos)

### 1. Extrair e Navegar

```bash
tar -xzf vizier_backend.tar.gz
cd vizier_backend
```

### 2. Copiar Arquivo de Ambiente

```bash
cp .env.example .env
```

### 3. Iniciar Servi√ßos

```bash
# Com Makefile (recomendado)
make build
make up

# Ou com Docker Compose diretamente
docker-compose build
docker-compose up -d
```

### 4. Verificar Status

```bash
# Ver logs
make logs

# Ou diretamente
docker-compose logs -f web

# Verificar health
curl http://localhost:8000/api/health/
```

### 5. Acessar Aplica√ß√£o

- **API**: http://localhost:8000
- **Health Check**: http://localhost:8000/api/health/
- **Admin**: http://localhost:8000/admin/ (sem credenciais por padr√£o)

## üîê Credenciais Necess√°rias

### 1. Vari√°veis de Ambiente B√°sicas

Edite o arquivo `.env` criado:

```bash
# Django
DEBUG=True
SECRET_KEY=dev-secret-key-change-in-production
ALLOWED_HOSTS=localhost,127.0.0.1,web

# Database (j√° configurado no docker-compose)
DATABASE_URL=postgresql://vizier_user:vizier_password@db:5432/vizier_med

# Redis (j√° configurado no docker-compose)
REDIS_URL=redis://redis:6379/0
```

### 2. AWS Cognito (Autentica√ß√£o)

**Op√ß√£o A: Desenvolvimento sem Cognito (Recomendado para come√ßar)**

```bash
# No .env, deixe em branco ou com valores dummy
COGNITO_REGION=us-east-1
COGNITO_USER_POOL_ID=us-east-1_dummy
COGNITO_CLIENT_ID=dummy_client_id
```

A autentica√ß√£o ser√° desativada em modo desenvolvimento. Use `force_authenticate` nos testes.

**Op√ß√£o B: Com Cognito Real (Produ√ß√£o)**

Se voc√™ j√° tem AWS Cognito configurado:

```bash
# 1. Ir para AWS Console
# https://console.aws.amazon.com/cognito/

# 2. Criar User Pool (se n√£o tiver)
# - Nome: vizier-med
# - Configurar pol√≠ticas de senha
# - Habilitar MFA (opcional)

# 3. Criar App Client
# - Nome: vizier-med-app
# - Anotar: User Pool ID e Client ID

# 4. Adicionar ao .env
COGNITO_REGION=us-east-1
COGNITO_USER_POOL_ID=us-east-1_xxxxxxxxx
COGNITO_CLIENT_ID=xxxxxxxxxxxxxxxxxxxxxxxxxx
```

**Como obter as credenciais:**

```bash
# AWS CLI
aws cognito-idp describe-user-pool --user-pool-id us-east-1_xxxxxxxxx --region us-east-1

# Ou via Console
# 1. AWS Console ‚Üí Cognito
# 2. User Pools ‚Üí Seu pool
# 3. General Settings ‚Üí Pool ID
# 4. App Clients ‚Üí Client ID
```

### 3. AWS S3 (Armazenamento)

**Op√ß√£o A: Desenvolvimento Local (Recomendado)**

```bash
# No .env, deixe em branco
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
S3_BUCKET=vizier-med-bucket-dev
```

Os arquivos ser√£o salvos localmente em `/tmp/vizier-med/`.

**Op√ß√£o B: Com S3 Real**

```bash
# 1. Criar bucket S3
aws s3 mb s3://vizier-med-bucket-dev --region us-east-1

# 2. Criar IAM User com permiss√µes S3
# AWS Console ‚Üí IAM ‚Üí Users ‚Üí Create User
# Adicionar policy: AmazonS3FullAccess

# 3. Gerar Access Key
# AWS Console ‚Üí IAM ‚Üí Users ‚Üí Seu usu√°rio ‚Üí Security Credentials

# 4. Adicionar ao .env
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
S3_BUCKET=vizier-med-bucket-dev
```

### 4. API de Infer√™ncia (Seu Servi√ßo)

**Configurar Endere√ßo da API:**

```bash
# No .env
INFERENCE_API_URL=http://localhost:8001
INFERENCE_API_TIMEOUT=300
```

**Onde colocar:**

1. **Arquivo `.env`** (mais f√°cil):
   ```env
   INFERENCE_API_URL=http://seu-servidor:porta
   INFERENCE_API_TIMEOUT=300
   ```

2. **Vari√°vel de ambiente**:
   ```bash
   export INFERENCE_API_URL=http://seu-servidor:porta
   docker-compose up
   ```

3. **docker-compose.yml** (editar diretamente):
   ```yaml
   environment:
     INFERENCE_API_URL: http://seu-servidor:porta
   ```

**Exemplo com diferentes APIs:**

```bash
# API local em outra porta
INFERENCE_API_URL=http://localhost:8001

# API em servidor remoto
INFERENCE_API_URL=https://api.seu-dominio.com

# API em container Docker (mesmo network)
INFERENCE_API_URL=http://inference-api:8001

# API em AWS
INFERENCE_API_URL=https://inference-api.us-east-1.amazonaws.com
```

## üìù Arquivo .env Completo para Desenvolvimento

```bash
# ==================== DJANGO ====================
DEBUG=True
SECRET_KEY=dev-secret-key-change-in-production
ALLOWED_HOSTS=localhost,127.0.0.1,web

# ==================== DATABASE ====================
# J√° configurado no docker-compose.yml
DATABASE_URL=postgresql://vizier_user:vizier_password@db:5432/vizier_med

# ==================== REDIS ====================
REDIS_URL=redis://redis:6379/0

# ==================== AWS COGNITO ====================
# Deixe em branco para desenvolvimento sem autentica√ß√£o
# Ou configure com valores reais
COGNITO_REGION=us-east-1
COGNITO_USER_POOL_ID=us-east-1_xxxxxxxxx
COGNITO_CLIENT_ID=xxxxxxxxxxxxxxxxxxxxxxxxxx

# ==================== AWS S3 ====================
# Deixe em branco para desenvolvimento local
# Ou configure com valores reais
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
S3_BUCKET=vizier-med-bucket-dev

# ==================== INFERENCE API ====================
# Seu servi√ßo de infer√™ncia
INFERENCE_API_URL=http://localhost:8001
INFERENCE_API_TIMEOUT=300

# ==================== DICOM PROCESSING ====================
DICOM_TARGET_HW=(512, 512)
DICOM_TARGET_SLICES=64
DICOM_WINDOW_CENTER=40
DICOM_WINDOW_WIDTH=400
```

## üîå Conectando sua API de Infer√™ncia

### 1. Entender o Fluxo

```
Django Backend
    ‚Üì
Recebe DICOM ZIP
    ‚Üì
Converte para NPZ
    ‚Üì
Envia para sua API (INFERENCE_API_URL)
    ‚Üì
Sua API processa
    ‚Üì
Django faz polling de status
    ‚Üì
Baixa resultados
    ‚Üì
Converte para NIfTI
    ‚Üì
Salva em S3
    ‚Üì
Retorna URL assinada
```

### 2. Endpoints Esperados da Sua API

Sua API deve ter estes endpoints:

**POST /jobs/submit**
```bash
# Request
curl -X POST http://seu-servidor:porta/jobs/submit \
  -F "file=@estudo.npz"

# Response
{
  "job_id": "job-123-abc",
  "status": "SUBMITTED"
}
```

**GET /jobs/{job_id}/status**
```bash
# Request
curl http://seu-servidor:porta/jobs/job-123-abc/status

# Response
{
  "job_id": "job-123-abc",
  "status": "PROCESSING",
  "progress": 45
}

# Ou quando completo
{
  "job_id": "job-123-abc",
  "status": "COMPLETED",
  "progress": 100
}
```

**GET /jobs/{job_id}/results**
```bash
# Request
curl http://seu-servidor:porta/jobs/job-123-abc/results \
  --output resultado.npz

# Response: arquivo bin√°rio NPZ
```

### 3. Exemplo: API Local em Python

Se voc√™ quer testar com uma API local:

**mock_inference_api.py**
```python
from flask import Flask, request, jsonify
import uuid
import time

app = Flask(__name__)
jobs = {}

@app.route('/jobs/submit', methods=['POST'])
def submit_job():
    file = request.files['file']
    job_id = str(uuid.uuid4())
    jobs[job_id] = {
        'status': 'PROCESSING',
        'progress': 0,
        'file': file.read()
    }
    return jsonify({'job_id': job_id, 'status': 'SUBMITTED'})

@app.route('/jobs/<job_id>/status', methods=['GET'])
def get_status(job_id):
    if job_id not in jobs:
        return jsonify({'error': 'Not found'}), 404
    
    job = jobs[job_id]
    # Simular progresso
    job['progress'] = min(100, job['progress'] + 10)
    if job['progress'] >= 100:
        job['status'] = 'COMPLETED'
    
    return jsonify({
        'job_id': job_id,
        'status': job['status'],
        'progress': job['progress']
    })

@app.route('/jobs/<job_id>/results', methods=['GET'])
def get_results(job_id):
    if job_id not in jobs:
        return jsonify({'error': 'Not found'}), 404
    
    return jobs[job_id]['file'], 200, {'Content-Type': 'application/octet-stream'}

if __name__ == '__main__':
    app.run(port=8001, debug=True)
```

**Executar:**
```bash
pip install flask
python mock_inference_api.py

# Em outro terminal
export INFERENCE_API_URL=http://localhost:8001
make up
```

### 4. Testar Conex√£o

```bash
# Verificar se API est√° acess√≠vel
curl http://seu-servidor:porta/jobs/test/status

# Ou via Django shell
docker-compose exec web python manage.py shell

# No shell Python
>>> from apps.inference.client import InferenceClient
>>> client = InferenceClient()
>>> client.get_status('test-job-id')
```

## üß™ Comandos √öteis de Desenvolvimento

### Makefile Commands

```bash
# Build e start
make build
make up

# Logs
make logs
make logs-db
make logs-redis

# Database
make migrate
make migrations
make createsuperuser

# Testes
make test
make coverage
make lint
make format

# Shell
make shell
make bash

# Parar
make down
```

### Docker Compose Direto

```bash
# Build
docker-compose build

# Start
docker-compose up -d

# Logs
docker-compose logs -f web

# Executar comando
docker-compose exec web python manage.py migrate

# Shell
docker-compose exec web python manage.py shell

# Parar
docker-compose down
```

## üêõ Troubleshooting

### Erro: "Cannot connect to database"

```bash
# Verificar se PostgreSQL est√° rodando
docker-compose ps

# Ver logs do banco
docker-compose logs db

# Reiniciar
docker-compose restart db
```

### Erro: "Port already in use"

```bash
# Encontrar processo na porta
lsof -i :8000

# Matar processo
kill -9 <PID>

# Ou mudar porta no docker-compose.yml
# ports:
#   - "8001:8000"  # Mudar 8000 para 8001
```

### Erro: "Module not found"

```bash
# Reinstalar depend√™ncias
docker-compose exec web pip install -r requirements.txt

# Ou rebuild
docker-compose build --no-cache
```

### Erro: "Permission denied"

```bash
# Verificar permiss√µes
docker-compose exec web ls -la /app

# Corrigir (se necess√°rio)
docker-compose exec -u root web chown -R appuser:appuser /app
```

### Erro: "DICOM processing failed"

```bash
# Verificar logs
docker-compose logs web | grep -i dicom

# Testar com arquivo DICOM v√°lido
# Certifique-se que o ZIP cont√©m pasta DICOM/ com arquivos .dcm
```

## üîç Verifica√ß√£o de Setup

### Health Check

```bash
# Verificar se tudo est√° rodando
curl http://localhost:8000/api/health/

# Resposta esperada:
# {"status": "healthy", "database": "connected", "redis": "connected"}
```

### Listar Endpoints

```bash
# Ver todas as rotas dispon√≠veis
docker-compose exec web python manage.py show_urls

# Ou acessar documenta√ß√£o
# http://localhost:8000/api/schema/swagger/
# http://localhost:8000/api/schema/redoc/
```

### Testar Autentica√ß√£o

```bash
# Sem Cognito (desenvolvimento)
curl -H "Authorization: Bearer dummy-token" \
  http://localhost:8000/api/auth/users/

# Com Cognito (produ√ß√£o)
# Obter token via Cognito
# Usar token no header
```

## üìö Pr√≥ximos Passos

1. **Configurar .env** com suas credenciais
2. **Executar `make up`** para iniciar
3. **Testar endpoints** via Postman ou curl
4. **Conectar sua API** de infer√™ncia
5. **Fazer upload de DICOM** para testar pipeline

## üéØ Checklist de Setup

- [ ] Docker e Docker Compose instalados
- [ ] Arquivo `.env` criado e configurado
- [ ] `make build` executado com sucesso
- [ ] `make up` iniciou todos os servi√ßos
- [ ] Health check retorna status "healthy"
- [ ] API de infer√™ncia est√° acess√≠vel
- [ ] Credenciais AWS configuradas (se usar S3 real)
- [ ] Cognito configurado (se usar autentica√ß√£o real)

## üìû Suporte

Se tiver d√∫vidas:

1. Verificar logs: `make logs`
2. Consultar documenta√ß√£o: `README.md`, `ARCHITECTURE.md`
3. Testar com curl: `curl http://localhost:8000/api/health/`
4. Abrir issue no GitHub

---

**Pronto para come√ßar!** üöÄ
